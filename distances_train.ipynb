{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "B5477WKpAb_t",
      "metadata": {
        "id": "B5477WKpAb_t"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (10,7)\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8j8zUWphAiXS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "8j8zUWphAiXS",
        "outputId": "ce2220af-9954-4729-f909-3bcda462ca8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'distances.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e4f650087f8c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset 'distances.csv' using pandas' read_csv function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#distances = pd.read_csv(r'C:\\Users\\jessi\\EE250_FinalProject_Talise_Jessica\\distances.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distances.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'distances.csv'"
          ]
        }
      ],
      "source": [
        "# Load the dataset 'distances.csv' using pandas' read_csv function.\n",
        "#distances = pd.read_csv(r'C:\\Users\\jessi\\EE250_FinalProject_Talise_Jessica\\distances.csv')\n",
        "distances = pd.read_csv('distances.csv')\n",
        "distances.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ge6ykGIBAjB5",
      "metadata": {
        "id": "Ge6ykGIBAjB5"
      },
      "outputs": [],
      "source": [
        "# Visualize the data distribution using a scatterplot\n",
        "sns.scatterplot(x=\"dist1\", y=\"dist2\", data=distances, hue=\"location\")\n",
        "plt.title(\"Scatterplot of Distances and Locations\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xihkq4n3AwhB",
      "metadata": {
        "id": "Xihkq4n3AwhB"
      },
      "outputs": [],
      "source": [
        "# [STUDENT SECTION: Prepare the data for training and testing]\n",
        "# 1. Data Preparation:\n",
        "# Prepare the input features (X)\n",
        "X = distances[[\"dist1\", \"dist2\"]].to_numpy()\n",
        "\n",
        "# Convert the denomination values (1 and 2) to binary labels (0 and 1) for binary classification.\n",
        "# Hint: Subtract 1 from the denomination values to convert them to 0 and 1.\n",
        "y = distances[[\"location\"]].to_numpy() # Change this\n",
        "\n",
        "#y = y - 1\n",
        "y = to_categorical(y)   # COnverts to one-hot encoding\n",
        "\n",
        "# Split the data into training and testing sets using train_test_split.\n",
        "# Use an 80/20 split for training and testing and random_state of 42.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Set the arguments for train_test_split\n",
        "\n",
        "# Normalize the input test and train features using StandardScaler to standardize reflectance and weight values.\n",
        "scaler = StandardScaler()\n",
        "# Use the scaler's fit_transform and transform methods to standardize the training and testing features.\n",
        "#  (See https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YhiFLmG9A1EG",
      "metadata": {
        "id": "YhiFLmG9A1EG"
      },
      "outputs": [],
      "source": [
        "# [STUDENT SECTION: Define and compile the model]\n",
        "# 2. Instantiate and Train the Model\n",
        "# - Build a neural network model using TensorFlow/Keras.\n",
        "# - The model should have:\n",
        "#    - An input layer with 2 input features (reflectance and weight).\n",
        "#    - 1 or 2 hidden layers with the number of neurons at your discretion (use 'relu' activation).\n",
        "#      (Experiment to find the best accuracy)\n",
        "#    - An output layer with 1 neuron and 'sigmoid' activation for binary classification.\n",
        "model = Sequential()\n",
        "# The next line gives an error, but the example code has the same error\n",
        "model.add(Dense(12, activation='relu', input_shape=(2,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# - Compile the model using Adam optimizer with a learning rate of 0.001,\n",
        "#   binary_crossentropy as the loss function, and 'accuracy' as the metric.\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#the above has nice accuracy\n",
        "\n",
        "\n",
        "# - Train the model using X_train and y_train.\n",
        "#    - Set validation_split to 0.2.\n",
        "#    - Use EarlyStopping with patience=5 to prevent overfitting.\n",
        "#    - Train the model for 100 epochs and use a batch size of 32.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "# call the appropriate function to train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ul-aEjVGKs-F",
      "metadata": {
        "id": "ul-aEjVGKs-F"
      },
      "source": [
        "**#experiement with the accuracy if used only 1 middle layer vs. 2 and so on**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E40g64bOA6Y_",
      "metadata": {
        "id": "E40g64bOA6Y_"
      },
      "outputs": [],
      "source": [
        "# [STUDENT SECTION: Evaluate the model]\n",
        "# Hint:\n",
        "# - Call model.evaluate() on the test set (X_test, y_test) and print the test accuracy.\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy = %.2f' %(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lS5QJfu3A-Z4",
      "metadata": {
        "id": "lS5QJfu3A-Z4"
      },
      "outputs": [],
      "source": [
        "# 4. Plot the Decision Boundary:\n",
        "# - Define a function to plot the decision boundary of the trained model. This function should take in the feature matrix X, the labels y, and the trained model.\n",
        "# - This function should:\n",
        "#    - Generate a mesh grid over the feature space (reflectance and weight).\n",
        "#    - Use the model to predict labels for each point in the mesh grid.\n",
        "#    - Plot the decision boundary using contourf.\n",
        "#    - Overlay the training data points using seaborn's scatterplot.\n",
        "def plot_decision_boundary(X, y, model):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = np.round(Z).reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.coolwarm)\n",
        "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y.flatten(), palette='bright', edgecolor=\"k\")\n",
        "    plt.xlabel('Distance 1')\n",
        "    plt.ylabel('Distance 2')\n",
        "    plt.title('Decision Boundary of the Multi-Class Classifier')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# [STUDENT SECTION: Call the function to plot the decision boundary by passing the correct arguments]\n",
        "plot_decision_boundary(X_train, y_train, model)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WacbNOMU88ye",
      "metadata": {
        "id": "WacbNOMU88ye"
      },
      "outputs": [],
      "source": [
        "# 5. Save the Trained Model:\n",
        "# - Save the trained model to a file named 'model.h5' using model.save().\n",
        "model.save('distmodel.h5')\n",
        "\n",
        "# [STUDENT SECTION: Save the model]\n",
        "\n",
        "# 6. Load the Saved Model and Use it to evalue the \"test\" data:\n",
        "# - Load the model using keras.models.load_model and re-evaluate it on the test data.\n",
        "new_model = load_model('distmodel.h5')\n",
        "test_loss, test_accuracy = new_model.evaluate(X_test, y_test)\n",
        "print('Accuracy = %.2f' %(test_accuracy*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eNMx7pSK_-TZ",
      "metadata": {
        "id": "eNMx7pSK_-TZ"
      },
      "outputs": [],
      "source": [
        "# 7. [STUDENT SECTION: Evaluate the loaded model on the test data]\n",
        "# the accuracy of the loaded model on the test data.  Examine the output\n",
        "# of predict and think about how to compute the accuracy of the predictions using\n",
        "# the y_test data.  Hint:  You may need to round the predictions to 0 or 1 using np.round()\n",
        "# When you use model.predict() in a binary classification problem, the output is usually\n",
        "# a 2D array where each element is a list containing a single predicted probability\n",
        "# (e.g., [[0.1], [0.9], [0.3], ...]). To compare these predictions to your 1D y_test array\n",
        "# (e.g., [0, 1, 0, ...]), you need to \"flatten()\" the 2D array into a 1D array.\n",
        "\n",
        "\n",
        "# print the accuracy of the loaded model on the test data\n",
        "\n",
        "# Evaluate the model on the test data using predict\n",
        "predictions = new_model.predict(X_test)\n",
        "predictions = np.round(predictions)\n",
        "predictions = predictions.flatten()\n",
        "\n",
        "# count how many are wrong\n",
        "count = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] != y_test[i]:\n",
        "        count += 1\n",
        "\n",
        "accuracy = 100 * (len(predictions) - count) / len(predictions)\n",
        "print('Accuracy = %.2f' %(accuracy))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}